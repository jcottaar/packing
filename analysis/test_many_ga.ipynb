{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "Will use 2 parallel processes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../core')\n",
    "sys.path.append('/packing/code/core/')\n",
    "\n",
    "import pack_runner\n",
    "import pack_ga2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import dill\n",
    "import importlib\n",
    "from multiprocess import Process, Queue, cpu_count\n",
    "import kaggle_support as kgs\n",
    "importlib.reload(pack_runner)\n",
    "\n",
    "# Configuration\n",
    "output_dir = '../../results/many_ga/'\n",
    "os.makedirs(output_dir + 'full/', exist_ok=True)\n",
    "os.makedirs(output_dir + 'abbr/', exist_ok=True)\n",
    "\n",
    "fast_mode = True  # Set to True for quick testing\n",
    "which_runner = pack_runner.baseline_runner  # Which example runner to use\n",
    "n_parallel_processes = 2 if kgs.env=='local' else 4\n",
    "print(f\"Will use {n_parallel_processes} parallel processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "git_commit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git commit: 31f9ad89\n"
     ]
    }
   ],
   "source": [
    "# Get git commit ID for tracking\n",
    "try:\n",
    "    import git\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    git_commit_id = repo.head.object.hexsha\n",
    "    print(f\"Git commit: {git_commit_id[:8]}\")\n",
    "except:\n",
    "    git_commit_id = 'no_git'\n",
    "    print(\"Git not available, using 'no_git' as commit ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "main_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 GPU(s)\n",
      "Starting parallel execution of 4 seeds using 2 processes\n",
      "Staggering process startup by 2 seconds each...\n",
      "\n",
      "Starting process for seed 0...\n",
      "local\n",
      "Seed 0 using GPU 0\n",
      "\n",
      "=== Starting seed 0 (Process 112411) ===\n",
      "{'seed': 0, 'n_generations': 10}\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 78 registers, 1264 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 78\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "Starting process for seed 1...\n",
      "\n",
      "All initial processes started. Monitoring for completion...\n",
      "\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, 1232 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "local\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 58 registers, 144 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 58\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:61: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n",
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:93: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  return from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1 using GPU 0\n",
      "\n",
      "=== Starting seed 1 (Process 112466) ===\n",
      "{'seed': 1, 'n_generations': 7}\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "Generation 0: Best costs = [[0.191464]]\n",
      "Generation 1: Best costs = [[0.176599]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 78 registers, 1264 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 78\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "Generation 2: Best costs = [[0.172237]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, 1232 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "Generation 3: Best costs = [[0.167801]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 58 registers, 144 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 58\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:61: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n",
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:93: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  return from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4: Best costs = [[0.167097]]\n",
      "Generation 5: Best costs = [[0.16447]]\n",
      "Generation 0: Best costs = [[0.192592]]\n",
      "Generation 6: Best costs = [[0.163267]]\n",
      "Generation 1: Best costs = [[0.176269]]\n",
      "Generation 7: Best costs = [[0.162235]]\n",
      "Generation 2: Best costs = [[0.172348]]\n",
      "Generation 8: Best costs = [[0.161857]]\n",
      "Generation 3: Best costs = [[0.167758]]\n",
      "Generation 9: Best costs = [[0.161123]]\n",
      "Runtime: 20.8s\n",
      "\n",
      "Seed 0 completed in 20.8s\n",
      "Best final costs: [0.16112264]\n",
      "Modifier values: {'seed': 0, 'n_generations': 10}\n",
      "Saved full: ../../results/many_ga/full/Baseline_0_31f9ad89_fast_f.pkl\n",
      "EXCEPTION in seed 0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_112365/1333788877.py\", line 73, in run_single_seed\n",
      "AttributeError: 'Runner' object has no attribute 'ga'\n",
      "\n",
      "\n",
      "*** Seed 0 failed: 'Runner' object has no attribute 'ga' ***\n",
      "\n",
      "Generation 4: Best costs = [[0.16529]]\n",
      "Starting process for seed 2...\n",
      "Generation 5: Best costs = [[0.16321]]\n",
      "local\n",
      "Generation 6: Best costs = [[0.160449]]\n",
      "Runtime: 18.2s\n",
      "\n",
      "Seed 1 completed in 18.2s\n",
      "Best final costs: [0.16044913]\n",
      "Modifier values: {'seed': 1, 'n_generations': 7}\n",
      "Saved full: ../../results/many_ga/full/Baseline_1_31f9ad89_fast_f.pkl\n",
      "EXCEPTION in seed 1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_112365/1333788877.py\", line 73, in run_single_seed\n",
      "AttributeError: 'Runner' object has no attribute 'ga'\n",
      "\n",
      "\n",
      "*** Seed 1 failed: 'Runner' object has no attribute 'ga' ***\n",
      "\n",
      "Waiting 2.8s before starting seed 3...\n",
      "Seed 2 using GPU 0\n",
      "\n",
      "=== Starting seed 2 (Process 112594) ===\n",
      "{'seed': 2, 'n_generations': 10}\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "Starting process for seed 3...\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 78 registers, 1264 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 78\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "local\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, 1232 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "Seed 3 using GPU 0\n",
      "\n",
      "=== Starting seed 3 (Process 112642) ===\n",
      "{'seed': 3, 'n_generations': 9}\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 58 registers, 144 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 58\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:61: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n",
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:93: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  return from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best costs = [[0.194554]]\n",
      "Generation 1: Best costs = [[0.175356]]\n",
      "Generation 2: Best costs = [[0.171445]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 78 registers, 1264 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 78\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "Generation 3: Best costs = [[0.165853]]\n",
      "Generation 4: Best costs = [[0.162788]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, 1232 bytes cumulative stack size, 420 bytes cmem[0], 24 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "Generation 5: Best costs = [[0.162431]]\n",
      "Generation 6: Best costs = [[0.16187]]\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 58 registers, 144 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 58\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:61: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n",
      "/mnt/d/packing/code/analysis/../core/pack_dynamics.py:93: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  return from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7: Best costs = [[0.161257]]\n",
      "Generation 0: Best costs = [[0.194061]]\n",
      "Generation 8: Best costs = [[0.160637]]\n",
      "Generation 1: Best costs = [[0.168757]]\n",
      "Generation 9: Best costs = [[0.159709]]\n",
      "Runtime: 19.0s\n",
      "\n",
      "Seed 2 completed in 19.0s\n",
      "Best final costs: [0.15970862]\n",
      "Modifier values: {'seed': 2, 'n_generations': 10}\n",
      "Saved full: ../../results/many_ga/full/Baseline_2_31f9ad89_fast_f.pkl\n",
      "EXCEPTION in seed 2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_112365/1333788877.py\", line 73, in run_single_seed\n",
      "AttributeError: 'Runner' object has no attribute 'ga'\n",
      "\n",
      "\n",
      "*** Seed 2 failed: 'Runner' object has no attribute 'ga' ***\n",
      "\n",
      "Generation 2: Best costs = [[0.16579]]\n",
      "Generation 3: Best costs = [[0.164462]]\n",
      "Generation 4: Best costs = [[0.162735]]\n",
      "Generation 5: Best costs = [[0.160397]]\n",
      "Generation 6: Best costs = [[0.158393]]\n",
      "Generation 7: Best costs = [[0.158303]]\n",
      "Generation 8: Best costs = [[0.157576]]\n",
      "Runtime: 23.6s\n",
      "\n",
      "Seed 3 completed in 23.6s\n",
      "Best final costs: [0.15757613]\n",
      "Modifier values: {'seed': 3, 'n_generations': 9}\n",
      "Saved full: ../../results/many_ga/full/Baseline_3_31f9ad89_fast_f.pkl\n",
      "EXCEPTION in seed 3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_112365/1333788877.py\", line 73, in run_single_seed\n",
      "AttributeError: 'Runner' object has no attribute 'ga'\n",
      "\n",
      "\n",
      "*** Seed 3 failed: 'Runner' object has no attribute 'ga' ***\n",
      "\n",
      "\n",
      "================================================================================\n",
      "All 4 seeds completed!\n",
      "Successful runs: 0\n",
      "Failed runs: 4\n"
     ]
    }
   ],
   "source": [
    "import kaggle_support as kgs\n",
    "kgs.profiling = False\n",
    "\n",
    "def run_single_seed(seed, which_runner, fast_mode, git_commit_id, output_dir, result_queue):\n",
    "    \"\"\"Worker function to run a single seed in a separate process\"\"\"\n",
    "    # Import everything needed in this worker process\n",
    "    import sys\n",
    "    sys.path.append('../core')\n",
    "    sys.path.append('/packing/code/core/')\n",
    "    \n",
    "    import numpy as np\n",
    "    import time\n",
    "    import copy\n",
    "    import os\n",
    "    import dill\n",
    "    \n",
    "    try:\n",
    "        # Set CUDA device based on process to avoid conflicts\n",
    "        # This helps if you have multiple GPUs\n",
    "        try:\n",
    "            import cupy as cp\n",
    "            # Use modulo to cycle through available GPUs\n",
    "            n_gpus = cp.cuda.runtime.getDeviceCount()\n",
    "            device_id = seed % n_gpus\n",
    "            cp.cuda.Device(device_id).use()\n",
    "            # Small delay to stagger CUDA initialization\n",
    "            time.sleep(0.5)\n",
    "            print(f'Seed {seed} using GPU {device_id}')\n",
    "        except Exception as e:\n",
    "            print(f'Warning: Could not set CUDA device for seed {seed}: {e}')\n",
    "        \n",
    "        print(f'\\n=== Starting seed {seed} (Process {os.getpid()}) ===')\n",
    "        \n",
    "        r = which_runner(fast_mode=fast_mode)\n",
    "        r.seed = seed\n",
    "        r.base_ga.ga.N_trees_to_do = 40\n",
    "        \n",
    "        # Check if this experiment already exists\n",
    "        base_filename = f\"{r.label}_{r.seed}_{git_commit_id[:8]}\"\n",
    "        if fast_mode:\n",
    "            base_filename += '_fast'\n",
    "        \n",
    "        # Run the experiment\n",
    "        start_time = time.time()\n",
    "        r.run()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if r.exception is not None:\n",
    "            print(f\"ERROR occurred in seed {seed}: {r.exception[:200]}\")\n",
    "            result_queue.put({'seed': seed, 'success': False, 'error': r.exception[:200]})\n",
    "            return\n",
    "        \n",
    "        # Get best costs for each configuration (tree sizes, etc.)\n",
    "        # r.best_costs is now shape (n_generations, n_configs) from pack_ga2 structure\n",
    "        best_costs_final = r.best_costs[-1, :]\n",
    "        print(f\"\\nSeed {seed} completed in {elapsed_time:.1f}s\")\n",
    "        print(f\"Best final costs: {best_costs_final}\")\n",
    "        print(f\"Modifier values: {r.modifier_values}\")\n",
    "        \n",
    "        # Create score string from average best cost\n",
    "        avg_cost = np.mean(best_costs_final)\n",
    "        score_str = f\"{avg_cost:.4f}\".replace('.', '_')\n",
    "        \n",
    "        # Save full version (with populations)\n",
    "        output_file_full = output_dir + 'full/' + base_filename + '_f.pkl'\n",
    "        with open(output_file_full, 'wb') as f:\n",
    "            dill.dump(r, f)\n",
    "        print(f\"Saved full: {output_file_full}\")\n",
    "        \n",
    "        # Save abbreviated version (without populations to save space)\n",
    "        r_abbr = copy.deepcopy(r)\n",
    "        #r_abbr.result_ga.ga.champions = []  # Clear champions to save space\n",
    "        r_abbr.result_ga.ga.abbreviate()\n",
    "        output_file_abbr = output_dir + 'abbr/' + base_filename + '_a.pkl'\n",
    "        with open(output_file_abbr, 'wb') as f:\n",
    "            dill.dump(r_abbr, f)\n",
    "        print(f\"Saved abbr: {output_file_abbr}\")\n",
    "        \n",
    "        # Put result data in queue for plotting\n",
    "        result_queue.put({\n",
    "            'seed': seed,\n",
    "            'success': True,\n",
    "            'label': r.label,\n",
    "            'best_costs': r.best_costs.copy(),\n",
    "            'n_configs': r.best_costs.shape[1],  # Number of configurations (tree sizes, etc.)\n",
    "            'avg_cost': avg_cost,\n",
    "            'elapsed_time': elapsed_time\n",
    "        })\n",
    "        \n",
    "        print(f\"Seed {seed} finished successfully!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = traceback.format_exc()\n",
    "        print(f\"EXCEPTION in seed {seed}:\\n{error_msg}\")\n",
    "        result_queue.put({'seed': seed, 'success': False, 'error': str(e)})\n",
    "\n",
    "\n",
    "# Main parallel execution\n",
    "n_seeds = 1000 if not fast_mode else 4\n",
    "result_queue = Queue()\n",
    "active_processes = []\n",
    "completed_results = []\n",
    "seeds_to_run = [a+0 for a in list(range(n_seeds))]\n",
    "next_seed_idx = 0\n",
    "\n",
    "# Limit parallel processes if using GPU (to avoid memory issues)\n",
    "# You may want to adjust this based on your GPU memory\n",
    "import cupy as cp\n",
    "n_gpus = cp.cuda.runtime.getDeviceCount()\n",
    "print(f\"Detected {n_gpus} GPU(s)\")\n",
    "\n",
    "# Adjust parallel processes - too many can overwhelm GPU memory\n",
    "# Start with 1-2 processes per GPU, adjust based on your GPU memory\n",
    "max_parallel = n_parallel_processes\n",
    "print(f\"Starting parallel execution of {n_seeds} seeds using {max_parallel} processes\")\n",
    "print(f\"Staggering process startup by 2 seconds each...\\n\")\n",
    "\n",
    "# Start initial batch of processes with staggered startup\n",
    "stagger_delay = 5.0  # seconds between each process start\n",
    "for i in range(min(max_parallel, n_seeds)):\n",
    "    seed = seeds_to_run[next_seed_idx]\n",
    "    print(f\"Starting process for seed {seed}...\")\n",
    "    p = Process(target=run_single_seed, args=(seed, which_runner, fast_mode, git_commit_id, output_dir, result_queue))\n",
    "    p.start()\n",
    "    active_processes.append((p, seed))\n",
    "    next_seed_idx += 1\n",
    "    \n",
    "    # Stagger the startup to avoid CUDA initialization conflicts\n",
    "    if i < min(max_parallel, n_seeds) - 1:  # Don't sleep after the last one\n",
    "        time.sleep(stagger_delay)\n",
    "\n",
    "print(f\"\\nAll initial processes started. Monitoring for completion...\\n\")\n",
    "\n",
    "# Track when we last started a process to stagger new starts\n",
    "last_process_start_time = time.time()\n",
    "\n",
    "# Main loop: wait for processes to complete and start new ones\n",
    "while active_processes or not result_queue.empty():\n",
    "    # Check for completed results in queue\n",
    "    while not result_queue.empty():\n",
    "        result = result_queue.get()\n",
    "        completed_results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"\\n*** Result received for seed {result['seed']}: avg_cost = {result['avg_cost']:.6f}, time = {result['elapsed_time']:.1f}s ***\\n\")\n",
    "            \n",
    "            # Plot convergence for this seed immediately\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            for i_config in range(result['n_configs']):\n",
    "                ax.plot(result['best_costs'][:, i_config], label=f'Config {i_config}')\n",
    "            ax.set_xlabel('Generation')\n",
    "            ax.set_ylabel('Best Cost')\n",
    "            ax.set_title(f\"Seed {result['seed']} - Final cost: {result['avg_cost']:.6f} (Time: {result['elapsed_time']:.1f}s)\")\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n*** Seed {result['seed']} failed: {result.get('error', 'Unknown error')} ***\\n\")\n",
    "    \n",
    "    # Check for finished processes and start new ones\n",
    "    for i in range(len(active_processes) - 1, -1, -1):\n",
    "        p, seed = active_processes[i]\n",
    "        if not p.is_alive():\n",
    "            p.join()\n",
    "            active_processes.pop(i)\n",
    "            \n",
    "            # Start a new process if there are more seeds to run\n",
    "            if next_seed_idx < n_seeds:\n",
    "                new_seed = seeds_to_run[next_seed_idx]\n",
    "                \n",
    "                # Stagger new process starts to avoid CUDA conflicts\n",
    "                time_since_last_start = time.time() - last_process_start_time\n",
    "                if time_since_last_start < stagger_delay:\n",
    "                    sleep_time = stagger_delay - time_since_last_start\n",
    "                    print(f\"Waiting {sleep_time:.1f}s before starting seed {new_seed}...\")\n",
    "                    time.sleep(sleep_time)\n",
    "                \n",
    "                print(f\"Starting process for seed {new_seed}...\")\n",
    "                new_p = Process(target=run_single_seed, args=(new_seed, which_runner, fast_mode, git_commit_id, output_dir, result_queue))\n",
    "                new_p.start()\n",
    "                active_processes.append((new_p, new_seed))\n",
    "                last_process_start_time = time.time()\n",
    "                next_seed_idx += 1\n",
    "    \n",
    "    # Small sleep to avoid busy waiting\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"All {n_seeds} seeds completed!\")\n",
    "print(f\"Successful runs: {sum(1 for r in completed_results if r['success'])}\")\n",
    "print(f\"Failed runs: {sum(1 for r in completed_results if not r['success'])}\")\n",
    "\n",
    "# Create summary plots for all successful runs\n",
    "successful_results = [r for r in completed_results if r['success']]\n",
    "if successful_results:\n",
    "    print(f\"\\nCreating summary plots for {len(successful_results)} successful runs...\")\n",
    "    \n",
    "    # Plot all convergence curves overlaid\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for result in successful_results:\n",
    "        for i_config in range(result['n_configs']):\n",
    "            ax.plot(result['best_costs'][:, i_config], alpha=0.3, linewidth=0.5, color='blue')\n",
    "    \n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Best Cost')\n",
    "    ax.set_title(f'GA Convergence - All {len(successful_results)} Runs (Overlaid)')\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot distribution of final costs\n",
    "    final_costs = [r['avg_cost'] for r in successful_results]\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.hist(final_costs, bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(np.mean(final_costs), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(final_costs):.6f}')\n",
    "    ax.axvline(np.min(final_costs), color='green', linestyle='--', linewidth=2, label=f'Best: {np.min(final_costs):.6f}')\n",
    "    ax.set_xlabel('Average Final Cost')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Distribution of Final Costs ({len(successful_results)} runs)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFinal Statistics:\")\n",
    "    print(f\"  Best cost:  {np.min(final_costs):.6f}\")\n",
    "    print(f\"  Worst cost: {np.max(final_costs):.6f}\")\n",
    "    print(f\"  Mean cost:  {np.mean(final_costs):.6f}\")\n",
    "    print(f\"  Std cost:   {np.std(final_costs):.6f}\")\n",
    "    print(f\"  Median cost: {np.median(final_costs):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 result files\n"
     ]
    }
   ],
   "source": [
    "# Optional: Load and analyze results\n",
    "results_files = sorted(glob.glob(output_dir + 'abbr/*.pkl'))\n",
    "print(f\"Found {len(results_files)} result files\")\n",
    "\n",
    "if len(results_files) > 0:\n",
    "    # Load all results\n",
    "    results = []\n",
    "    for f in results_files:\n",
    "        with open(f, 'rb') as fp:\n",
    "            results.append(dill.load(fp))\n",
    "    \n",
    "    # Extract hyperparameters and final costs\n",
    "    hyperparams = []\n",
    "    final_costs = []\n",
    "    \n",
    "    for r in results:\n",
    "        if r.exception is None and r.best_costs is not None:\n",
    "            hyperparams.append(r.modifier_values)\n",
    "            # r.best_costs is shape (n_generations, n_configs)\n",
    "            # Average across all configs for overall score\n",
    "            final_costs.append(np.mean(r.best_costs[-1, :]))\n",
    "    \n",
    "    print(f\"\\nSuccessfully completed runs: {len(final_costs)}\")\n",
    "    if len(final_costs) > 0:\n",
    "        print(f\"Best average cost: {np.min(final_costs):.6f}\")\n",
    "        print(f\"Worst average cost: {np.max(final_costs):.6f}\")\n",
    "        print(f\"Mean average cost: {np.mean(final_costs):.6f}\")\n",
    "        print(f\"Std average cost: {np.std(final_costs):.6f}\")\n",
    "        \n",
    "        # Plot distribution of final costs\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.hist(final_costs, bins=20, edgecolor='black')\n",
    "        plt.xlabel('Average Final Cost')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Distribution of Final Costs Across Hyperparameter Settings')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
