{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743f2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "WARNING: CUDA MPS not active\n",
      "False\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 8.710 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 421.094 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 80 registers, used 1 barriers, 1264 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 368.594 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 80\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 9.217 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 422.548 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, used 1 barriers, 1232 bytes cumulative stack size, 420 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 72.298 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 8.959 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 413.246 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 56 registers, used 1 barriers, 144 bytes cumulative stack size, 420 bytes cmem[0], 40 bytes cmem[2]\n",
      "ptxas info    : Compile time = 83.735 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 56\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/core/pack_dynamics.py:60: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building lookup table for CollisionCostOverlappingArea...\n",
      "Building LUT: 700 x 700 x 50 = 24,500,000 grid points\n",
      "  Processing theta 1/50\n",
      "Cost range: [0.000000, 0.223521]\n",
      "Trimming zero edges:\n",
      "  X: 700 -> 562 (removed 138)\n",
      "  Y: 700 -> 651 (removed 49)\n",
      "  Theta: 50 -> 50 (removed 0)\n",
      "  Total reduction: 25.3% (6,206,900 points)\n",
      "Compiling CUDA LUT kernel (USE_TEXTURE=False, one-time only)\n",
      "Detected GPU compute capability: 89 (arch=sm_89)\n",
      "Compiling: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -lineinfo -arch=sm_89 -cubin /mnt/d//packing/temp/pack_cuda_lut_saved.cu -o /mnt/d//packing/temp/pack_cuda_lut.cubin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "nvcc compilation failed:\n/mnt/d//packing/temp/pack_cuda_lut_saved.cu:5: warning: \"M_PI\" redefined\n    5 | #define M_PI 3.14159265358979323846f\n      | \nIn file included from /usr/include/c++/13/cmath:47,\n                 from /usr/include/c++/13/math.h:36,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/math_functions.h:4577,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/common_functions.h:303,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:117,\n                 from <command-line>:\n/usr/include/math.h:1152: note: this is the location of the previous definition\n 1152 | # define M_PI           3.14159265358979323846  /* pi */\n      | \n/mnt/d//packing/temp/pack_cuda_lut_saved.cu(293): error: expected a \";\"\n      for (int i = ref_index+1 i < n; ++i) {\n                               ^\n\n/mnt/d//packing/temp/pack_cuda_lut_saved.cu(293): error: expected a \";\"\n      for (int i = ref_index+1 i < n; ++i) {\n                                         ^\n\n2 errors detected in the compilation of \"/mnt/d//packing/temp/pack_cuda_lut_saved.cu\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpack_test\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mpack_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregenerate_reference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_test.py:24\u001b[39m, in \u001b[36mrun_all_tests\u001b[39m\u001b[34m(regenerate_reference)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_all_tests\u001b[39m(regenerate_reference=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     23\u001b[39m     kgs.debugging_mode = \u001b[32m2\u001b[39m    \n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mtest_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregenerate_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     test_ga(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m     test_costs()        \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_test.py:46\u001b[39m, in \u001b[36mtest_ga\u001b[39m\u001b[34m(regenerate_reference, do_resume)\u001b[39m\n\u001b[32m     44\u001b[39m ga.ga.do_legalize = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_resume:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mga\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     res = ga.ga.population.fitness\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_ga3.py:1342\u001b[39m, in \u001b[36mOrchestrator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28mself\u001b[39m._current_generation = \u001b[38;5;28mself\u001b[39m._current_generation\n\u001b[32m   1341\u001b[39m offspring_list = \u001b[38;5;28mself\u001b[39m.ga.generate_offspring(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_relax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffspring_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28mself\u001b[39m.ga.merge_offspring()\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.ga.score(register_best=\u001b[38;5;28;01mTrue\u001b[39;00m)            \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_ga3.py:1294\u001b[39m, in \u001b[36mOrchestrator._relax\u001b[39m\u001b[34m(self, sol_list)\u001b[39m\n\u001b[32m   1292\u001b[39m         s.genotype.h[:] = s.phenotype.h[:]\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m relaxer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rough_relaxers:\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m     \u001b[43mpack_dynamics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_simulation_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelaxer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.genotype_at == \u001b[32m1\u001b[39m:\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sol_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_dynamics.py:663\u001b[39m, in \u001b[36mrun_simulation_list\u001b[39m\u001b[34m(simulator, solution_list)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m N_trees, group_sols \u001b[38;5;129;01min\u001b[39;00m groups.items():\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(group_sols) == \u001b[32m1\u001b[39m:\n\u001b[32m    662\u001b[39m         \u001b[38;5;66;03m# Single solution - just run directly and continue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         result = \u001b[43msimulator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_sols\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m         group_sols[\u001b[32m0\u001b[39m].xyt[:] = result.xyt\n\u001b[32m    665\u001b[39m         group_sols[\u001b[32m0\u001b[39m].h[:] = result.h\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_dynamics.py:97\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(self, sol)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlbfgs_torch_parallel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m results = \u001b[43mlbfgs_torch_parallel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlbfgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance_change\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance_rel_change\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtolerance_rel_change\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhistory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mline_search_fn\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrong_wolfe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_on_cost_increase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop_on_cost_increase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m x_result = cp.from_dlpack(to_dlpack(results))\n\u001b[32m    101\u001b[39m sol.xyt = cp.ascontiguousarray(x_result[:,:sol.N_trees*\u001b[32m3\u001b[39m].reshape(sol.N_solutions,-\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/lbfgs_torch_parallel.py:437\u001b[39m, in \u001b[36mlbfgs\u001b[39m\u001b[34m(func, x0, lr, max_iter, max_eval, tolerance_grad, tolerance_change, tolerance_rel_change, stop_on_cost_increase, history_size, line_search_fn, max_step)\u001b[39m\n\u001b[32m    434\u001b[39m x = x0.detach().clone()\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# Evaluate initial function and gradient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m loss, flat_grad = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# loss: (M,), flat_grad: (M, N)\u001b[39;00m\n\u001b[32m    438\u001b[39m func_evals = torch.ones(M, dtype=torch.long, device=device)\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Track which systems are still active\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_dynamics.py:82\u001b[39m, in \u001b[36mOptimizerBFGS.run_simulation.<locals>.f_torch\u001b[39m\u001b[34m(x, is_main_loop)\u001b[39m\n\u001b[32m     79\u001b[39m sol_tmp.xyt = tmp_xyt[:N, :]\n\u001b[32m     80\u001b[39m sol_tmp.h = tmp_h[:N, :]\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_cost\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_grad\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_grad_h\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_cost:\n\u001b[32m     85\u001b[39m     cost_history.append(tmp_cost[:N].get())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cost.py:52\u001b[39m, in \u001b[36mCost.compute_cost\u001b[39m\u001b[34m(self, sol, cost, grad_xyt, grad_bound, evaluate_gradient)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, sol:kgs.SolutionCollection, cost:cp.ndarray, grad_xyt:cp.ndarray, grad_bound:cp.ndarray, evaluate_gradient:\u001b[38;5;28mbool\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Subclass can implement faster version with preallocated gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_xyt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_gradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaling != \u001b[32m1.0\u001b[39m:\n\u001b[32m     54\u001b[39m         cost *= \u001b[38;5;28mself\u001b[39m.scaling\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cost.py:113\u001b[39m, in \u001b[36mCostCompound._compute_cost\u001b[39m\u001b[34m(self, sol, cost, grad_xyt, grad_bound, evaluate_gradient)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m._temp_grad_xyt[:] = \u001b[32m0\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m._temp_grad_bound[:] = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_temp_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_temp_grad_xyt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_temp_grad_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_gradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m cost += \u001b[38;5;28mself\u001b[39m._temp_cost\n\u001b[32m    115\u001b[39m grad_xyt += \u001b[38;5;28mself\u001b[39m._temp_grad_xyt\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cost.py:52\u001b[39m, in \u001b[36mCost.compute_cost\u001b[39m\u001b[34m(self, sol, cost, grad_xyt, grad_bound, evaluate_gradient)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, sol:kgs.SolutionCollection, cost:cp.ndarray, grad_xyt:cp.ndarray, grad_bound:cp.ndarray, evaluate_gradient:\u001b[38;5;28mbool\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Subclass can implement faster version with preallocated gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_xyt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_gradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaling != \u001b[32m1.0\u001b[39m:\n\u001b[32m     54\u001b[39m         cost *= \u001b[38;5;28mself\u001b[39m.scaling\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cost.py:365\u001b[39m, in \u001b[36mCollisionCost._compute_cost\u001b[39m\u001b[34m(self, sol, cost, grad_xyt, grad_bound, evaluate_gradient)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# Pass LUT directly (fast - updates constants only if changed)\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m evaluate_gradient:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[43mpack_cuda_lut\u001b[49m\u001b[43m.\u001b[49m\u001b[43moverlap_multi_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxyt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_xyt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m     grad_bound[:] = \u001b[32m0\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cuda_lut.py:952\u001b[39m, in \u001b[36moverlap_multi_ensemble\u001b[39m\u001b[34m(xyt, out_cost, lut, out_grads, stream)\u001b[39m\n\u001b[32m    933\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute total overlap sum for multiple ensembles in parallel using LUT.\u001b[39;00m\n\u001b[32m    934\u001b[39m \n\u001b[32m    935\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    948\u001b[39m \u001b[33;03m    CUDA stream for kernel execution.\u001b[39;00m\n\u001b[32m    949\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _last_lut_id\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m \u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# Update constant memory only if LUT changed (cache by object ID)\u001b[39;00m\n\u001b[32m    955\u001b[39m lut_id = \u001b[38;5;28mid\u001b[39m(lut)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_cuda_lut.py:907\u001b[39m, in \u001b[36m_ensure_initialized\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    904\u001b[39m proc = subprocess.run(cmd, text=\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proc.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnvcc compilation failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mproc.stderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proc.stderr:\n\u001b[32m    910\u001b[39m     \u001b[38;5;28mprint\u001b[39m(proc.stderr)\n",
      "\u001b[31mRuntimeError\u001b[39m: nvcc compilation failed:\n/mnt/d//packing/temp/pack_cuda_lut_saved.cu:5: warning: \"M_PI\" redefined\n    5 | #define M_PI 3.14159265358979323846f\n      | \nIn file included from /usr/include/c++/13/cmath:47,\n                 from /usr/include/c++/13/math.h:36,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/math_functions.h:4577,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/common_functions.h:303,\n                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:117,\n                 from <command-line>:\n/usr/include/math.h:1152: note: this is the location of the previous definition\n 1152 | # define M_PI           3.14159265358979323846  /* pi */\n      | \n/mnt/d//packing/temp/pack_cuda_lut_saved.cu(293): error: expected a \";\"\n      for (int i = ref_index+1 i < n; ++i) {\n                               ^\n\n/mnt/d//packing/temp/pack_cuda_lut_saved.cu(293): error: expected a \";\"\n      for (int i = ref_index+1 i < n; ++i) {\n                                         ^\n\n2 errors detected in the compilation of \"/mnt/d//packing/temp/pack_cuda_lut_saved.cu\".\n"
     ]
    }
   ],
   "source": [
    "#%%pyinstrument\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'core'))\n",
    "import pack_test\n",
    "\n",
    "import importlib\n",
    "pack_test.run_all_tests(regenerate_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b102228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'NVIDIA GeForce RTX 4070 Ti' 8 9\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "prop = cp.cuda.runtime.getDeviceProperties(0)\n",
    "print(prop['name'], prop['major'], prop['minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599dea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dd79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
