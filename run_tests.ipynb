{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "WARNING: CUDA MPS not active\n",
      "False\n",
      "init CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling kernel variant: crystal ===\n",
      "Defines: ENABLE_CRYSTAL_AXES, ENABLE_OVERLAP_AREA, ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_CRYSTAL_AXES -DENABLE_OVERLAP_AREA -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_crystal.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 10.451 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 427.557 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1264 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 80 registers, used 1 barriers, 1264 bytes cumulative stack size, 424 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 380.556 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [crystal] ---\n",
      "  Max threads per block (kernel): 768\n",
      "  Num registers: 80\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1264\n",
      "=== Compiling kernel variant: no_sep ===\n",
      "Defines: ENABLE_OVERLAP_AREA\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_OVERLAP_AREA -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_no_sep.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 8.989 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 432.009 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    1232 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 64 registers, used 1 barriers, 1232 bytes cumulative stack size, 424 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 80.294 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [no_sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 64\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 1232\n",
      "=== Compiling kernel variant: sep ===\n",
      "Defines: ENABLE_SEPARATION\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -DENABLE_SEPARATION -cubin /mnt/d//packing/temp/pack_cuda_saved.cu -o /mnt/d//packing/temp/pack_cuda_sep.cubin\n",
      "ptxas info    : 0 bytes gmem, 1172 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function 'multi_boundary_distance_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_distance_list_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 36 registers, used 1 barriers, 404 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compile time = 9.104 ms\n",
      "ptxas info    : Compiling entry function 'multi_boundary_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_boundary_list_total\n",
      "    240 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 43 registers, used 1 barriers, 240 bytes cumulative stack size, 404 bytes cmem[0], 32 bytes cmem[2]\n",
      "ptxas info    : Compile time = 437.125 ms\n",
      "ptxas info    : Compiling entry function 'multi_overlap_list_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_list_total\n",
      "    144 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 56 registers, used 1 barriers, 144 bytes cumulative stack size, 424 bytes cmem[0], 40 bytes cmem[2]\n",
      "ptxas info    : Compile time = 80.323 ms\n",
      "\n",
      "\n",
      "--- Kernel: multi_overlap_list_total [sep] ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 56\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 144\n",
      "\n",
      "--- Kernel: multi_boundary_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 43\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 240\n",
      "\n",
      "--- Kernel: multi_boundary_distance_list_total ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 36\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 1172\n",
      "  Local memory (bytes): 0\n",
      "Loading cached lookup table from /mnt/d//packing/temp//lut_cache/exact_sep_Nx900_Ny900_Nt50_trimTrue_tree42d0f17d.lut_cache...\n",
      "Successfully loaded cached lookup table\n",
      "Compiling CUDA LUT kernel one-time only)\n",
      "Detected GPU compute capability: 89 (arch=sm_89)\n",
      "Compiling: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -lineinfo -arch=sm_89 -cubin /mnt/d//packing/temp/pack_cuda_lut_saved.cu -o /mnt/d//packing/temp/pack_cuda_lut.cubin\n",
      "/mnt/d//packing/temp/pack_cuda_lut_saved.cu:5: warning: \"M_PI\" redefined\n",
      "    5 | #define M_PI 3.14159265358979323846f\n",
      "      | \n",
      "In file included from /usr/include/c++/13/cmath:47,\n",
      "                 from /usr/include/c++/13/math.h:36,\n",
      "                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/math_functions.h:4577,\n",
      "                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/crt/common_functions.h:303,\n",
      "                 from /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:117,\n",
      "                 from <command-line>:\n",
      "/usr/include/math.h:1152: note: this is the location of the previous definition\n",
      " 1152 | # define M_PI           3.14159265358979323846  /* pi */\n",
      "      | \n",
      "ptxas info    : 16 bytes gmem, 64 bytes cmem[3], 16 bytes cmem[4]\n",
      "ptxas info    : Compiling entry function 'multi_overlap_lut_total' for 'sm_89'\n",
      "ptxas info    : Function properties for multi_overlap_lut_total\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 48 registers, used 1 barriers, 408 bytes cmem[0]\n",
      "ptxas info    : Compile time = 11.666 ms\n",
      "\n",
      "Kernel multi_overlap_lut_total:\n",
      "  Registers: 48\n",
      "  Shared mem: 0 bytes\n",
      "  Max threads/block: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/packing/code/core/pack_dynamics.py:61: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  x0 = from_dlpack(x0.toDlpack())\n",
      "/mnt/d/packing/code/core/pack_dynamics.py:93: VisibleDeprecationWarning: This function is deprecated and will be removed in a future release. Use the cupy.from_dlpack() array constructor instead.\n",
      "  return from_dlpack(tmp_cost[:N].toDlpack()), from_dlpack(res.toDlpack())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LAP CUDA\n",
      "Detected GPU compute capability: 8.9 (arch=sm_89)\n",
      "GPU max threads per block: 1024\n",
      "=== Compiling LAP kernels ===\n",
      "Command: /usr/local/cuda/bin/nvcc -O3 -use_fast_math --extra-device-vectorization --ptxas-options=-v,--warn-on-spills -arch=sm_89 -cubin /mnt/d//packing/temp/lap_batch_saved.cu -o /mnt/d//packing/temp/lap_batch.cubin\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function 'diversity_shortcut_kernel' for 'sm_89'\n",
      "ptxas info    : Function properties for diversity_shortcut_kernel\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 29 registers, used 1 barriers, 400 bytes cmem[0]\n",
      "ptxas info    : Compile time = 10.316 ms\n",
      "ptxas info    : Compiling entry function 'compute_costs' for 'sm_89'\n",
      "ptxas info    : Function properties for compute_costs\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 29 registers, used 0 barriers, 384 bytes cmem[0]\n",
      "ptxas info    : Compile time = 3.969 ms\n",
      "ptxas info    : Compiling entry function 'auction_kernel' for 'sm_89'\n",
      "ptxas info    : Function properties for auction_kernel\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 35 registers, used 0 barriers, 412 bytes cmem[0]\n",
      "ptxas info    : Compile time = 7.570 ms\n",
      "ptxas info    : Compiling entry function 'hungarian_kernel' for 'sm_89'\n",
      "ptxas info    : Function properties for hungarian_kernel\n",
      "    1808 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, used 0 barriers, 1808 bytes cumulative stack size, 408 bytes cmem[0]\n",
      "ptxas info    : Compile time = 16.560 ms\n",
      "\n",
      "\n",
      "--- Kernel: hungarian_kernel ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 40\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 0\n",
      "  Local memory (bytes): 1808\n",
      "\n",
      "--- Kernel: auction_kernel ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 35\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 0\n",
      "  Local memory (bytes): 0\n",
      "\n",
      "--- Kernel: compute_costs ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 29\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 0\n",
      "  Local memory (bytes): 0\n",
      "\n",
      "--- Kernel: diversity_shortcut_kernel ---\n",
      "  Max threads per block (kernel): 1024\n",
      "  Num registers: 29\n",
      "  Shared memory (bytes): 0\n",
      "  Const memory (bytes): 0\n",
      "  Local memory (bytes): 0\n",
      "Generation 0: Best costs = [[0.382838, 0.010458]]\n",
      "Generation 1: Best costs = [[0.382838, 0.002625]]\n",
      "Generation 2: Best costs = [[0.382838, 0.001407]]\n",
      "Generation 3: Best costs = [[0.382838, 0.001064]]\n",
      "Generation 4: Best costs = [[0.382838, 4.8e-05]]\n",
      "Loading cached lookup table from /mnt/d//packing/temp//lut_cache/exact_sep_Nx900_Ny900_Nt50_trimTrue_tree42d0f17d.lut_cache...\n",
      "Successfully loaded cached lookup table\n",
      "Generation 0: Best costs = [[0.382838, 0.010458]]\n",
      "Generation 1: Best costs = [[0.382838, 0.002625]]\n",
      "Generation 2: Best costs = [[0.382838, 0.001407]]\n",
      "Loading cached lookup table from /mnt/d//packing/temp//lut_cache/exact_sep_Nx900_Ny900_Nt50_trimTrue_tree42d0f17d.lut_cache...\n",
      "Successfully loaded cached lookup table\n",
      "Generation 3: Best costs = [[0.382838, 0.001064]]\n",
      "Generation 4: Best costs = [[0.382838, 4.8e-05]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "GA test failed: final fitness does not match reference.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#pack_test.test_costs()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mpack_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregenerate_reference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_test.py:25\u001b[39m, in \u001b[36mrun_all_tests\u001b[39m\u001b[34m(regenerate_reference)\u001b[39m\n\u001b[32m     23\u001b[39m kgs.debugging_mode = \u001b[32m2\u001b[39m   \n\u001b[32m     24\u001b[39m test_ga(regenerate_reference, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtest_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m      \n\u001b[32m     26\u001b[39m test_costs()               \n\u001b[32m     27\u001b[39m pack_cuda_primitives_test.run_all_tests()    \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/packing/code/core/pack_test.py:58\u001b[39m, in \u001b[36mtest_ga\u001b[39m\u001b[34m(regenerate_reference, do_resume)\u001b[39m\n\u001b[32m     56\u001b[39m     kgs.dill_save(kgs.code_dir + \u001b[33m'\u001b[39m\u001b[33mref_ga.pickle\u001b[39m\u001b[33m'\u001b[39m, res)\n\u001b[32m     57\u001b[39m ref = kgs.dill_load(kgs.code_dir + \u001b[33m'\u001b[39m\u001b[33mref_ga.pickle\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.all(ref==res), \u001b[33m\"\u001b[39m\u001b[33mGA test failed: final fitness does not match reference.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: GA test failed: final fitness does not match reference."
     ]
    }
   ],
   "source": [
    "#%%pyinstrument\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'core'))\n",
    "import pack_test\n",
    "\n",
    "import importlib\n",
    "#pack_test.test_costs()\n",
    "pack_test.run_all_tests(regenerate_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b102228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'NVIDIA GeForce RTX 4070 Ti' 8 9\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "prop = cp.cuda.runtime.getDeviceProperties(0)\n",
    "print(prop['name'], prop['major'], prop['minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599dea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dd79e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
